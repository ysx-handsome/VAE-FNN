{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67f3d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Lambda, Concatenate, Dropout, Layer, Add, Multiply, RepeatVector\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.losses import mse, mae\n",
    "from sklearn.model_selection import train_test_split #cross_validation\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45c34a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regu = 1e-4 #float(sys.argv[2]) #for NN\n",
    "regu2 = 1e-4 #float(sys.argv[3]) #for decoder weights\n",
    "regu1 = -1 #for encoder weights\n",
    "\n",
    "\n",
    "#regu = 0.0005\n",
    "layer1 = 5 # decoder layers\n",
    "nodes1 = 32 # decoder nodes\n",
    "\n",
    "layer2 = 1 # encoder layers\n",
    "nodes2 =  32 # encoder nodes\n",
    "\n",
    "mc_samples = 200\n",
    "batch_size = 512  # batch size is 512 for initial fit\n",
    "epochs = 100\n",
    "epsilon_std = 1.0\n",
    "##noise = 0.2/np.sqrt(2) # for x, 0.1**2 #\n",
    "prior_mean = 0\n",
    "prior_var = 0.5\n",
    "laplace = False\n",
    "noisex = 0.05 # {0.05,0.1,0.2}\n",
    "#beta = float(sys.argv[3])\n",
    "sy = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3309fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_train = np.loadtxt('simu_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f465aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = np.zeros((3, 7)) #NN_train_ise, NN_test_ise, train_ise, t`rain_ll, test_ise, NN_test_iae, test_iae\n",
    "#best_predict = np.zeros((test_dat.shape[0], 2))\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "ise_min = 1e8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d4d2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layer, nodes, activ ='relu', input_dim = 1, output_dim = 1, regu = -1, alpha = 0.3):\n",
    "    model = Sequential()\n",
    "    if regu > 0:\n",
    "        model.add(Dense(nodes, input_dim=input_dim, activation=activ, \n",
    "                        kernel_regularizer=regularizers.l2(regu), bias_regularizer=regularizers.l2(regu))) #, kernel_initializer='he_normal', bias_initializer='he_normal'))\n",
    "        for l in np.arange(layer):\n",
    "            model.add(Dense(nodes, input_dim=nodes, activation=activ, \n",
    "                            kernel_regularizer=regularizers.l2(regu), bias_regularizer=regularizers.l2(regu)))#, kernel_initializer='he_normal', bias_initializer='he_normal'))\n",
    "        model.add(Dense(output_dim, input_dim=nodes, kernel_regularizer=regularizers.l2(regu)))\n",
    "    elif activ == 'leakyrelu':\n",
    "        model.add(Dense(nodes, input_dim=input_dim))\n",
    "        model.add(LeakyReLU(alpha = alpha))\n",
    "        for l in np.arange(layer):\n",
    "            model.add(Dense(nodes, input_dim=nodes))\n",
    "            model.add(LeakyReLU(alpha = alpha))\n",
    "        model.add(Dense(output_dim, input_dim=nodes))\n",
    "    else:\n",
    "        model.add(Dense(nodes, input_dim=input_dim, activation=activ)) \n",
    "        for l in np.arange(layer):\n",
    "            model.add(Dense(nodes, input_dim=nodes, activation=activ))\n",
    "        model.add(Dense(output_dim, input_dim=nodes))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f0933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class changeNoise(Callback):\n",
    "    def __init__(self, noisey, noise):\n",
    "        super(changeNoise, self).__init__()\n",
    "        self.noisey = noisey \n",
    "        self.noise = noise\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #print(\"Setting noisey to =\", str(K.get_value(self.noisey)))\n",
    "        if epoch > 19: #and epoch % 10 == 0:   \n",
    "            K.set_value(self.noisey,logs.get('mise2')) #\n",
    "#        if epoch == 200:  \n",
    "#          K.set_value(self.noise, 0.3**2)\n",
    "#         elif epoch == 600:  \n",
    "#           K.set_value(self.noise, 0.2**2)\n",
    "        \n",
    "\n",
    "noisey =  K.variable(0.1)\n",
    "noise = K.variable(noisex**2)\n",
    "#if anneal:\n",
    "#\tnoise =  K.variable(0.1**2)\n",
    "#else:\n",
    "#\tnoise =  K.variable(0.3**2)\n",
    "noiseparam = changeNoise(noisey, noise) # will change according to \"noise\", \"noisey\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce10dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossLayer(Layer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(LossLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #z_mu0, z_log_var0, z, x_pred, x1, y1\n",
    "        mu, log_var, z, fz, w, y = inputs\n",
    "       \n",
    "        w = K.expand_dims(w, axis = 1)\n",
    "        y = K.expand_dims(y, axis = 1)\n",
    "        \n",
    "        if laplace:\n",
    "            reconstruction_loss = K.sum(K.square(y - fz), axis=-1)/noisey/2 + K.sum(K.abs(w - z), axis=-1) /noise\n",
    "        else:\n",
    "            reconstruction_loss = K.sum(K.square(y - fz), axis=-1)/noisey/2 + K.sum(K.square(w - z), axis=-1) /noise/2\n",
    "       \n",
    "        prior_loss = 1.5 * K.log(1 + K.square(z - prior_mean)/prior_var/2) # v = 2\n",
    "        prior_loss = K.sum(prior_loss, axis=-1)\n",
    "        \n",
    "        post_loss = .5 * (K.square(mu - z) /K.exp(log_var) + log_var)\n",
    "        post_loss = K.sum(post_loss, axis=-1)\n",
    "      \n",
    "        return  reconstruction_loss + prior_loss - post_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20050a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightLayer(Layer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(WeightLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, loss):\n",
    "        \n",
    "        log_weight = K.stop_gradient(-loss)\n",
    "        print(log_weight.shape,'weightlayer')\n",
    "        #print()\n",
    "        log_weight -= K.max(log_weight,axis = 1,keepdims= True)\n",
    "        \n",
    "        weight = K.exp(log_weight)\n",
    "        weight = weight/K.sum(weight,axis = 1,keepdims= True)\n",
    "        \n",
    "\n",
    "        return  weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a4d427",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name='dense_83_input'), name='dense_83_input', description=\"created by layer 'dense_83_input'\"), but it was called on an input with incompatible shape (None, 200, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name='dense_87_input'), name='dense_87_input', description=\"created by layer 'dense_87_input'\"), but it was called on an input with incompatible shape (None, 200, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='dense_71_input'), name='dense_71_input', description=\"created by layer 'dense_71_input'\"), but it was called on an input with incompatible shape (None, 200, 2).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='dense_71_input'), name='dense_71_input', description=\"created by layer 'dense_71_input'\"), but it was called on an input with incompatible shape (None, 200, 2).\n",
      "(None, 200) weightlayer\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_2\" expects 6 input(s), but it received 4 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 2) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 2) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f5daf8bba0d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     history = vae.fit([X_train[:,latent_dim:(latent_dim*2+1)],X_train[:,(latent_dim+1):(latent_dim*2+1)],\n\u001b[0m\u001b[0;32m    118\u001b[0m     X_train[:,latent_dim:(latent_dim*2)], X_train[:,latent_dim*2]],\n\u001b[0;32m    119\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\86189\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_2\" expects 6 input(s), but it received 4 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 2) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 2) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(3): # repeat \n",
    "\n",
    "    model0 = build_model(layer1, nodes1, input_dim = latent_dim, activ='relu', regu = regu) # alpha for leaky relu\n",
    "\n",
    "    ada = adam_v2.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0004, amsgrad=False)\n",
    "\n",
    "    model0.compile(loss=mse,optimizer=ada)  \n",
    "    #model0.summary()\n",
    "\n",
    "    history = model0.fit( X_train[:,latent_dim : (2*latent_dim)] , X_train[:,2*latent_dim],  #0: latent_dim\n",
    "                       #validation_data=(X_val[:,latent_dim : (2*latent_dim)], X_val[:,2*latent_dim]), \n",
    "      batch_size=np.min([512,X_train.shape[0]]),epochs=200,verbose=0, shuffle=True) #, callbacks=[checkpointer]\n",
    "\n",
    "    '''\n",
    "    model00_predict = model0.predict(test_dat[:,0:latent_dim])\n",
    "    results[i, 1] = np.mean((model00_predict.transpose() - test_dat[:,latent_dim])**2)\n",
    "    results[i, 0] = history.history['loss'][-1]\n",
    "    #np.mean((model0.predict(X_val[:,latent_dim : (2*latent_dim)]).transpose() - X_val[:,2*latent_dim])**2) \n",
    "    '''\n",
    "    org_weight = model0.get_weights()\n",
    "\n",
    "    if sy < 0.3:\n",
    "        K.set_value(noisey, 0.1)\n",
    "    else:\n",
    "        K.set_value(noisey, 0.2)\n",
    "\n",
    "    model1 = build_model(layer1, nodes1, input_dim = latent_dim, activ='relu', regu = regu2)\n",
    "\n",
    "    model1.set_weights(org_weight)\n",
    "\n",
    "\n",
    "    x = Input(shape=(latent_dim + 1,))\n",
    "    x2 = Input(shape=(latent_dim,))\n",
    "    x1 = Input(shape=(latent_dim,))\n",
    "    y1 = Input(shape=(1,))\n",
    "\n",
    "    model_mu = build_model(layer2, nodes2, activ='relu', regu = regu1, input_dim = latent_dim+1, output_dim = 1) #x1\n",
    "    z_mu1 = model_mu(x)\n",
    "    #z_mu = Add()([z_mu, x1])\n",
    "\n",
    "    model_var = build_model(layer2-1, nodes2, activ='relu', regu = regu1, input_dim = latent_dim+1, output_dim = 1)\n",
    "    z_log_var1 = model_var(x)\n",
    "\n",
    "    z_sigma1 = Lambda(lambda t: K.exp(.5*t))(z_log_var1)\n",
    "\n",
    "    eps1 = Input(tensor=K.random_normal(stddev=epsilon_std, shape=(K.shape(x)[0],mc_samples, 1)))\n",
    "\n",
    "    z_eps1 = Multiply()([z_sigma1, eps1])\n",
    "    z1 = Add()([z_mu1, z_eps1])\n",
    "\n",
    "    model_mu2 = build_model(layer2+1, nodes2, activ='relu', regu = regu1, input_dim = latent_dim+1, output_dim = 1) #x2\n",
    "    model_var2 = build_model(layer2-1, nodes2, activ='relu', regu = regu1, input_dim = latent_dim+1, output_dim = 1)\n",
    "\n",
    "    input2 = Concatenate()([RepeatVector(mc_samples)(x2), z1])  # x need expand_dim\n",
    "\n",
    "    z_mu2 = model_mu2(input2)\n",
    "    z_log_var2 = model_var2(input2)\n",
    "\n",
    "    z_sigma2 = Lambda(lambda t: K.exp(.5*t))(z_log_var2)\n",
    "    eps2 = Input(tensor=K.random_normal(stddev=epsilon_std, shape=(K.shape(x)[0],\n",
    "                                        mc_samples, 1)))\n",
    "\n",
    "    z_eps2 = Multiply()([z_sigma2, eps2])\n",
    "    z2 = Add()([z_mu2, z_eps2])\n",
    "\n",
    "\n",
    "    z = Concatenate()([z1, z2])\n",
    "    x_pred =  model1(z) \n",
    "\n",
    "    #encoder = Model([x,eps1], [z_mu1,z_log_var1,model_mu2()])\n",
    "\n",
    "    z_mu1 = RepeatVector(mc_samples)(z_mu1)\n",
    "    z_log_var1 = RepeatVector(mc_samples)(z_log_var1)\n",
    "\n",
    "    z_mu = Concatenate()([z_mu1, z_mu2])\n",
    "    z_log_var = Concatenate()([z_log_var1, z_log_var2])\n",
    "\n",
    "\n",
    "    z_mu0 = K.stop_gradient(z_mu)\n",
    "    z_log_var0 = K.stop_gradient(z_log_var)\n",
    "    z0 = K.stop_gradient(z)\n",
    "    x0_pred =  model1(z0)\n",
    "\n",
    "    vae_loss = LossLayer(name='LossLayer')([z_mu0, z_log_var0, z, x_pred, x1, y1]) \n",
    "    weight = WeightLayer(trainable = False,name='WeightLayer')(vae_loss) \n",
    "\n",
    "    output = Concatenate()([z, x_pred])\n",
    "    vae = Model(inputs=[x,x2,x1, y1,eps1, eps2], outputs=output) # batch * MC * (latent_dim + 1)\n",
    "\n",
    "\n",
    "    def mise2(yTrue, yPred):\n",
    "        var_y = K.sum(K.square(yTrue[:,:,latent_dim:(latent_dim+1)]- yPred[:,:,latent_dim:(latent_dim+1)]), axis=-1)\n",
    "\n",
    "        return K.mean(K.sum(var_y * weight, axis = 1))\n",
    "\n",
    "\n",
    "    def customLoss(yTrue, yPred):\n",
    "        loss = K.sum(vae_loss * K.square(weight), axis = 1) \n",
    "\n",
    "        reconstruction_loss0 =  (K.sum(K.square(yTrue[:,:,latent_dim:(latent_dim+1)]- x0_pred), axis=-1)) /noisey/2\n",
    "        reconstruction_loss0 = K.sum(reconstruction_loss0 * (weight - K.square(weight)), axis = 1) \n",
    "\n",
    "\n",
    "        if laplace:      \n",
    "            return K.mean(loss + reconstruction_loss0, axis = 0) + K.log(noise)*latent_dim + K.log(noisey)/2\n",
    "        else:\n",
    "            return K.mean(loss + reconstruction_loss0, axis = 0) + K.log(noise)*latent_dim/2 + K.log(noisey)/2\n",
    "\n",
    "\n",
    "    ada = adam_v2.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0004, amsgrad=False) #0.005 for noisex = 0.005\n",
    "\n",
    "    vae.compile(optimizer=ada, loss=customLoss, metrics = [mise2]) #rmsprop,  weight_entropy\n",
    "    #vae.summary() \n",
    "\n",
    "\n",
    "\n",
    "    history = vae.fit([X_train[:,latent_dim:(latent_dim*2+1)],X_train[:,(latent_dim+1):(latent_dim*2+1)],\n",
    "    X_train[:,latent_dim:(latent_dim*2)], X_train[:,latent_dim*2]],\n",
    "    np.expand_dims(X_train[:,latent_dim:(latent_dim*2+1)], axis=1),\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    verbose = 0, \n",
    "    batch_size=np.min([batch_size,X_train.shape[0]]),\n",
    "    #   validation_data=(\n",
    "    #       [X_val[:,latent_dim:(latent_dim*2+1)],X_val[:,latent_dim:(latent_dim*2)],X_val[:,latent_dim*2]],\n",
    "    #       np.expand_dims(X_val[:,latent_dim:(latent_dim*2+1)], axis=1)\n",
    "    #   ),\n",
    "    callbacks=[noiseparam ])\n",
    "\n",
    "    model0_predict = model1.predict(test_dat[:,0:(latent_dim)]) \n",
    "    results[i, 4] = np.mean((model0_predict.transpose() - test_dat[:,latent_dim])**2)\n",
    "    results[i, 6] = np.mean(np.abs(model0_predict.transpose() - test_dat[:,latent_dim]))\n",
    "    results[i, 5] = np.mean(np.abs(model00_predict.transpose() - test_dat[:,latent_dim]))\n",
    "\n",
    "    results[i, 3] = history.history['loss'][-1]\n",
    "    results[i, 2] = history.history['mise2'][-1]\n",
    "\n",
    "    if results[i,4] < ise_min:\n",
    "        best_predict[:,1] = model0_predict[:,0]\n",
    "        best_predict[:,0] = model00_predict[:,0]\n",
    "        ise_min = results[i,4]\n",
    "\n",
    "\n",
    "filename = prefix + \"_\" + repeat + \"_\" + str(noisex) +\"_\" +str(n)\n",
    "np.savetxt(filename + \".txt\", results)\n",
    "# save prediction\n",
    "if repeat == '0':\n",
    "    np.savetxt(filename + \"_prediction.txt\", best_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a1b356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 200, 2) dtype=float32 (created by layer 'tf.stop_gradient_4')>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_log_var0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "793fa9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 200, 2) dtype=float32 (created by layer 'concatenate_6')>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c48c06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 200, 1) dtype=float32 (created by layer 'sequential_7')>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06137fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'input_9')>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a94307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_10')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cd57f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 0.21939293,  1.3781114 ],\n",
       "       [-0.38145253,  0.6621349 ],\n",
       "       [-1.7369822 , -1.5247327 ]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=K.random_normal(stddev=epsilon_std, shape=(3,2))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e61ebfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[ 1.3781114],\n",
       "       [ 0.6621349],\n",
       "       [-1.5247327]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.max(loss,axis = 1,keepdims= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597f209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
